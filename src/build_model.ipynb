{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset/train_dataset.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>category</th>\n",
       "      <th>card_number</th>\n",
       "      <th>age</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>6.300000e+11</td>\n",
       "      <td>54</td>\n",
       "      <td>66.21</td>\n",
       "      <td>22</td>\n",
       "      <td>49879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.540000e+15</td>\n",
       "      <td>15</td>\n",
       "      <td>55.81</td>\n",
       "      <td>14</td>\n",
       "      <td>62668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>5.020000e+11</td>\n",
       "      <td>60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>4</td>\n",
       "      <td>96037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>3.530000e+15</td>\n",
       "      <td>44</td>\n",
       "      <td>89.52</td>\n",
       "      <td>40</td>\n",
       "      <td>29911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350000e+15</td>\n",
       "      <td>72</td>\n",
       "      <td>1.90</td>\n",
       "      <td>38</td>\n",
       "      <td>16421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_hour  trans_day  trans_month  trans_year  category   card_number  \\\n",
       "0           0          1            1        2019        12  6.300000e+11   \n",
       "1           1          1            1        2019         3  3.540000e+15   \n",
       "2           3          1            1        2019         8  5.020000e+11   \n",
       "3           6          1            1        2019         4  3.530000e+15   \n",
       "4           6          1            1        2019         0  2.350000e+15   \n",
       "\n",
       "   age  trans_amount  state    zip  fraud_risk  \n",
       "0   54         66.21     22  49879           0  \n",
       "1   15         55.81     14  62668           0  \n",
       "2   60          8.68      4  96037           0  \n",
       "3   44         89.52     40  29911           0  \n",
       "4   72          1.90     38  16421           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[ : , : 10].values\n",
    "y = dataset.iloc[ : , 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10210, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1802, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = np.count_nonzero(y_train == 1)\n",
    "valid = np.count_nonzero(y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud cases in training data = 5106\n",
      "Valid cases in training data = 5104\n"
     ]
    }
   ],
   "source": [
    "print('Fraud cases in training data =', fraud)\n",
    "print('Valid cases in training data =', valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66337259,  1.24104545,  0.45653094, -0.37826057,  0.83408097,\n",
       "        -0.30554032,  2.3966382 , -0.73068363,  0.0181697 , -0.77660466],\n",
       "       [-1.6023747 , -0.07304053, -0.90455674, -0.37826057, -1.22335066,\n",
       "        -0.30836573,  0.74498916, -0.74861649,  0.64443135,  0.93890762],\n",
       "       [-1.12537527,  0.1459738 ,  0.45653094, -0.37826057,  0.57690202,\n",
       "        -0.30362247,  1.18542891, -0.79511806,  0.78360061, -1.2179066 ],\n",
       "       [-1.6023747 , -0.29205486, -0.36012167, -0.37826057, -0.70899275,\n",
       "        -0.30397763,  1.46070375, -0.51118115, -1.58227676,  1.76478537],\n",
       "       [-0.7676257 , -0.29205486, -1.44899181, -0.37826057, -0.70899275,\n",
       "        -0.30836532, -0.08083536,  0.02559291,  0.78360061, -1.18526965]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02112216, -0.51106919,  1.27318354, -0.37826057,  1.34843888,\n",
       "         3.15638262,  0.35960438,  1.60624238,  0.64443135,  0.91726066],\n",
       "       [-0.05212655,  0.58400246,  0.1843134 , -0.37826057,  0.83408097,\n",
       "        -0.30822372, -0.08083536, -0.65192446,  0.29650821, -1.52769864],\n",
       "       [ 1.14037202,  1.56956694,  0.72874847, -0.37826057,  1.09125992,\n",
       "        -0.30560345,  1.29553884,  1.71351642,  1.13152375,  1.07356281],\n",
       "       [ 1.02112216, -0.73008352,  0.1843134 , -0.37826057,  1.09125992,\n",
       "        -0.30500363,  1.51575871,  1.6205402 ,  0.15733896,  0.77172649],\n",
       "       [-1.6023747 , -0.07304053, -0.08790413, -0.37826057,  1.34843888,\n",
       "        -0.30819767,  0.80004413, -0.06571388, -0.60809196,  0.84854544]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[ : 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression(random_state = 0)\n",
    "LR_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8485016648168702\n"
     ]
    }
   ],
   "source": [
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NEAREST NEIGHBORS (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "KNN_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657047724750278\n"
     ]
    }
   ],
   "source": [
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM_model = SVC(kernel = 'linear', random_state = 0)\n",
    "SVM_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVM_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_svm = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8479467258601554\n"
     ]
    }
   ],
   "source": [
    "print(acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8496115427302997\n"
     ]
    }
   ],
   "source": [
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DT_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dt = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967258601553829\n"
     ]
    }
   ],
   "source": [
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9705882352941176\n"
     ]
    }
   ],
   "source": [
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARTIFICIAL NEURAL NETWORK (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.add(tf.keras.layers.Dense(64, input_dim = 10, activation = 'relu'))\n",
    "ANN_model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "ANN_model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "320/320 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7848\n",
      "Epoch 2/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8532\n",
      "Epoch 3/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8604\n",
      "Epoch 4/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8578\n",
      "Epoch 5/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 0.8622\n",
      "Epoch 6/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.8675\n",
      "Epoch 7/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8706\n",
      "Epoch 8/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2643 - accuracy: 0.8806\n",
      "Epoch 9/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2739 - accuracy: 0.8755\n",
      "Epoch 10/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.8765\n",
      "Epoch 11/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.8826\n",
      "Epoch 12/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.8851\n",
      "Epoch 13/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.8971\n",
      "Epoch 14/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.9060\n",
      "Epoch 15/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9096\n",
      "Epoch 16/200\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.91 - 0s 1ms/step - loss: 0.2097 - accuracy: 0.9156\n",
      "Epoch 17/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9132\n",
      "Epoch 18/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.9230\n",
      "Epoch 19/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9206\n",
      "Epoch 20/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.9309\n",
      "Epoch 21/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1732 - accuracy: 0.9318\n",
      "Epoch 22/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1698 - accuracy: 0.9302\n",
      "Epoch 23/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.9272\n",
      "Epoch 24/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9363\n",
      "Epoch 25/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9382\n",
      "Epoch 26/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.9405\n",
      "Epoch 27/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.9411\n",
      "Epoch 28/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1526 - accuracy: 0.9409\n",
      "Epoch 29/200\n",
      "320/320 [==============================] - 0s 985us/step - loss: 0.1434 - accuracy: 0.9438\n",
      "Epoch 30/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1384 - accuracy: 0.9466\n",
      "Epoch 31/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9481\n",
      "Epoch 32/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9447\n",
      "Epoch 33/200\n",
      "320/320 [==============================] - 0s 995us/step - loss: 0.1318 - accuracy: 0.9484\n",
      "Epoch 34/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.9519\n",
      "Epoch 35/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.9534\n",
      "Epoch 36/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9502\n",
      "Epoch 37/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9467\n",
      "Epoch 38/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9414\n",
      "Epoch 39/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9517\n",
      "Epoch 40/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1194 - accuracy: 0.9515\n",
      "Epoch 41/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9559\n",
      "Epoch 42/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9526\n",
      "Epoch 43/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9553\n",
      "Epoch 44/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9560\n",
      "Epoch 45/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9546\n",
      "Epoch 46/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9572\n",
      "Epoch 47/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9597\n",
      "Epoch 48/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9505\n",
      "Epoch 49/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.9558\n",
      "Epoch 50/200\n",
      "320/320 [==============================] - 0s 994us/step - loss: 0.1084 - accuracy: 0.9581\n",
      "Epoch 51/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9566\n",
      "Epoch 52/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.9539\n",
      "Epoch 53/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9567\n",
      "Epoch 54/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1082 - accuracy: 0.9578\n",
      "Epoch 55/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9629\n",
      "Epoch 56/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.9571\n",
      "Epoch 57/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9642\n",
      "Epoch 58/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.9611\n",
      "Epoch 59/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9563\n",
      "Epoch 60/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9660\n",
      "Epoch 61/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9607\n",
      "Epoch 62/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.1016 - accuracy: 0.9611\n",
      "Epoch 64/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.9616\n",
      "Epoch 65/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0939 - accuracy: 0.9635\n",
      "Epoch 66/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9665\n",
      "Epoch 67/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9638\n",
      "Epoch 68/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.9629\n",
      "Epoch 69/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9661\n",
      "Epoch 70/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0984 - accuracy: 0.9603\n",
      "Epoch 71/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9657\n",
      "Epoch 72/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9630\n",
      "Epoch 73/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9675\n",
      "Epoch 74/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9696\n",
      "Epoch 75/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9693\n",
      "Epoch 76/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.9662\n",
      "Epoch 77/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9666\n",
      "Epoch 78/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9657\n",
      "Epoch 79/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9685\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9698\n",
      "Epoch 81/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9726\n",
      "Epoch 82/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9732\n",
      "Epoch 83/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9677\n",
      "Epoch 84/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9659\n",
      "Epoch 85/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9653\n",
      "Epoch 86/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0807 - accuracy: 0.9665\n",
      "Epoch 87/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0759 - accuracy: 0.9681\n",
      "Epoch 88/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9709\n",
      "Epoch 89/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9682\n",
      "Epoch 90/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9723\n",
      "Epoch 91/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9720\n",
      "Epoch 92/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9738\n",
      "Epoch 93/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9732\n",
      "Epoch 94/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9623\n",
      "Epoch 95/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9721\n",
      "Epoch 96/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9731\n",
      "Epoch 97/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.9663\n",
      "Epoch 98/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0671 - accuracy: 0.9730\n",
      "Epoch 99/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0750 - accuracy: 0.9694\n",
      "Epoch 100/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9781\n",
      "Epoch 101/200\n",
      "320/320 [==============================] - 0s 992us/step - loss: 0.0732 - accuracy: 0.9715\n",
      "Epoch 102/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9735\n",
      "Epoch 103/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9782\n",
      "Epoch 104/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0632 - accuracy: 0.9777\n",
      "Epoch 105/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9768\n",
      "Epoch 106/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.9735\n",
      "Epoch 107/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.9775\n",
      "Epoch 108/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.9686\n",
      "Epoch 109/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9770\n",
      "Epoch 110/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9745\n",
      "Epoch 111/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0601 - accuracy: 0.9784\n",
      "Epoch 112/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0608 - accuracy: 0.9791\n",
      "Epoch 113/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9758\n",
      "Epoch 114/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9784\n",
      "Epoch 115/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9750\n",
      "Epoch 116/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9752\n",
      "Epoch 117/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9789\n",
      "Epoch 118/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9759\n",
      "Epoch 119/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9776\n",
      "Epoch 120/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0689 - accuracy: 0.9761\n",
      "Epoch 121/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9799\n",
      "Epoch 122/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9786\n",
      "Epoch 123/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9779\n",
      "Epoch 124/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9785\n",
      "Epoch 125/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0690 - accuracy: 0.9728\n",
      "Epoch 126/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9803\n",
      "Epoch 127/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9742\n",
      "Epoch 128/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9783\n",
      "Epoch 129/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9826\n",
      "Epoch 130/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9845\n",
      "Epoch 131/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9751\n",
      "Epoch 132/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9800\n",
      "Epoch 133/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9816\n",
      "Epoch 134/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9823\n",
      "Epoch 135/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9772\n",
      "Epoch 136/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9821\n",
      "Epoch 137/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9834\n",
      "Epoch 138/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9828\n",
      "Epoch 139/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9819\n",
      "Epoch 140/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9818\n",
      "Epoch 141/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0509 - accuracy: 0.9776\n",
      "Epoch 142/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9785\n",
      "Epoch 143/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9812\n",
      "Epoch 144/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9824\n",
      "Epoch 145/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9837\n",
      "Epoch 146/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9844\n",
      "Epoch 147/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9845\n",
      "Epoch 148/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9850\n",
      "Epoch 149/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9848\n",
      "Epoch 150/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9774\n",
      "Epoch 151/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9855\n",
      "Epoch 152/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9846\n",
      "Epoch 153/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9813\n",
      "Epoch 154/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0417 - accuracy: 0.9824\n",
      "Epoch 155/200\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.98 - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9851\n",
      "Epoch 156/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9848\n",
      "Epoch 157/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9836\n",
      "Epoch 158/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9857: 0s - loss: 0.0363 - accu\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9872\n",
      "Epoch 160/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9882\n",
      "Epoch 161/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9873\n",
      "Epoch 162/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9835\n",
      "Epoch 163/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9819\n",
      "Epoch 164/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9875\n",
      "Epoch 165/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9865\n",
      "Epoch 166/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9890\n",
      "Epoch 167/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9841\n",
      "Epoch 168/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 169/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9873\n",
      "Epoch 170/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9871\n",
      "Epoch 171/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9867\n",
      "Epoch 172/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9852\n",
      "Epoch 173/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 174/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9878\n",
      "Epoch 175/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9893\n",
      "Epoch 176/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9893\n",
      "Epoch 177/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9867\n",
      "Epoch 178/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9865\n",
      "Epoch 179/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9888\n",
      "Epoch 180/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9874\n",
      "Epoch 181/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 182/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0352 - accuracy: 0.9881\n",
      "Epoch 183/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9893\n",
      "Epoch 184/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9894\n",
      "Epoch 185/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9909\n",
      "Epoch 186/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0309 - accuracy: 0.9889\n",
      "Epoch 187/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9861\n",
      "Epoch 188/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9900\n",
      "Epoch 189/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9918\n",
      "Epoch 190/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9816\n",
      "Epoch 191/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9933\n",
      "Epoch 192/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9917\n",
      "Epoch 193/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9938\n",
      "Epoch 194/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9899\n",
      "Epoch 195/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9917\n",
      "Epoch 196/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9889\n",
      "Epoch 197/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9824\n",
      "Epoch 198/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9938\n",
      "Epoch 199/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9925\n",
      "Epoch 200/200\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c56862beb0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_model.fit(x_train, y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc_ann = ANN_model.evaluate(x_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994025468826294\n"
     ]
    }
   ],
   "source": [
    "print(acc_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ANN_model.predict(x_test)\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "y_pred[y_pred > 0.5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY COMPARISON OF ALL THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [acc_lr * 100,\n",
    "          acc_knn * 100,\n",
    "          acc_svm * 100,\n",
    "          acc_nb * 100,\n",
    "          acc_dt * 100,\n",
    "          acc_rf * 100,\n",
    "          acc_ann * 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Artificial Neural Network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Algorithm Name'] = names\n",
    "df['Accuracy Score (%)'] = scores\n",
    "df = df.sort_values('Accuracy Score (%)', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm Name</th>\n",
       "      <th>Accuracy Score (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial Neural Network</td>\n",
       "      <td>99.402547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>97.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>96.725860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>86.570477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>84.961154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>84.850166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>84.794673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm Name  Accuracy Score (%)\n",
       "6  Artificial Neural Network           99.402547\n",
       "5              Random Forest           97.058824\n",
       "4              Decision Tree           96.725860\n",
       "1        K-Nearest Neighbors           86.570477\n",
       "3                Naive Bayes           84.961154\n",
       "0        Logistic Regression           84.850166\n",
       "2     Support Vector Machine           84.794673"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.subplots(figsize = (10, 5))\n",
    "ax = sns.barplot(x = \"Accuracy Score (%)\", y = \"Algorithm Name\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE BEST TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('../model/project_model.h5') is False:\n",
    "    ANN_model.save('../model/project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
